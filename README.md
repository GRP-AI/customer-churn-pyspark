# Customer Churn Prediction using PySpark and Pandas

## ğŸ“Œ Project Overview
This project builds a churn prediction pipeline using PySpark and Pandas in Databricks. 
After uploading and cleaning the data, a Random Forest model is trained and evaluated using accuracy and classification metrics. 
The workflow demonstrates scalable data processing and efficient ML modeling in a cloud-native setup.

## ğŸ§° Tools & Technologies
- Databricks
- PySpark
- Pandas
- Scikit-learn
- Python

## ğŸ“Š Workflow Steps
1. Data ingestion from Spark table
2. Conversion to Pandas DataFrame
3. Data cleaning and preprocessing
4. Feature engineering
5. Model training (Random Forest)
6. Evaluation using accuracy, precision, recall, F1-score

## ğŸ“ Files
- `Customer_Churn_Prediction.ipynb`: Main notebook containing the full pipeline
- `README.md`: Project summary and instructions

## ğŸš€ How to Run
1. Open the notebook in Databricks
2. Upload your dataset or use the provided Spark table
3. Run each cell sequentially to reproduce the results

## ğŸ“¬ Contact
For questions or feedback, feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/gangaram-pandey/) or leave a comment in the repository.

